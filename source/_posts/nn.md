---
title: torch.nn常见函数总结
date: 2025-07-16
categories: 
    - 科研
tags: 
    - Pytorch
---

---
## 激活函数
1. **ReLU（Rectified Linear Unit）**
   - 作用：将输入中的负值全部置零，正值保持不变，常用于隐藏层。
   - 数学公式：
     $$
     \mathrm{ReLU}(x) = \max(0, x)
     $$

2. **LeakyReLU**
   - 作用：为了解决 ReLU 在负区间梯度为 0 的问题，LeakyReLU 在负区间给一个很小的斜率（如 0.01）。
   - 数学公式：
     $$
     \mathrm{LeakyReLU}(x) = 
     \begin{cases}
     x, & \text{if } x \geq 0 \\
     \alpha x, & \text{if } x < 0
     \end{cases}
     $$
     其中 $\alpha$ 通常取 0.01。

3. **Sigmoid**
   - 作用：将输入映射到 (0, 1) 区间，常用于二分类的输出层。
   - 数学公式：
     $$
     \sigma(x) = \frac{1}{1 + e^{-x}}
     $$

4. **Tanh（双曲正切）**
   - 作用：将输入映射到 (-1, 1) 区间，常用于隐藏层。
   - 数学公式：
     $$
     \tanh(x) = \frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}
     $$

5. **Softmax**
   - 作用：将一个向量归一化为概率分布，常用于多分类的输出层。
   - 数学公式（对第 $i$ 个元素）：
     $$
     \mathrm{Softmax}(x_i) = \frac{e^{x_i}}{\sum_{j=1}^{n} e^{x_j}}
     $$
     其中 $x$ 是输入向量，$n$ 是向量的长度。

---
## 填充函数

**ReflectionPad2d**
- **作用**：对输入的四个边界使用反射填充（即边界外的值为边界内的镜像），常用于卷积前的边缘处理，减少边界效应。
- **常见参数**：
  - `padding`：int 或 4 元组，指定每个边的填充大小。例如 `padding=1` 或 `padding=(1, 2, 3, 4)` 分别对应左、右、上、下的填充。



**ZeroPad2d**
- **作用**：对输入的四个边界使用零填充，常用于卷积神经网络中保持特征图尺寸或控制感受野。
- **常见参数**：
  - `padding`：int 或 4 元组，指定每个边的填充大小。例如 `padding=2` 或 `padding=(1, 2, 3, 4)`。

---
## 归一化函数
**InstanceNorm2d**
- **作用**：对每个样本的每个通道分别做归一化，常用于风格迁移等任务，能提升模型的泛化能力。
- **常见参数**：
  - `num_features`：输入的通道数（即 C）。
  - `eps`：为防止除零而加到分母上的一个很小的数，默认 1e-5。


---
## 卷积函数
**Conv2d**
- **作用**：二维卷积层，是 CNN 的核心操作，用于提取空间特征，假设图像尺寸为 $(H, W)$，卷积核尺寸为 $(h, w)$，步长为s，填充为p，膨胀系数为d，则输出尺寸为
$$
H_{out}=⌊\frac {H+2×p−(d×(h−1)+1)} {s}⌋+1 \\
W_{out}=⌊\frac {W+2×p−(d×(w−1)+1)} {s}⌋+1
 $$

- **常见参数**：
  - `in_channels`：输入通道数。
  - `out_channels`：输出通道数（卷积核个数）。
  - `kernel_size`：卷积核尺寸，可以是单个 int 或 (h, w) 元组。
  - `stride`：步幅，默认 1。
  - `padding`：填充，默认 0。
  - `dilation`：膨胀系数，默认 1，即填充在卷积核内部的空间。
  - `groups`：分组卷积，默认 1。
  - `bias`：是否有偏置项，默认 True。

---

## 损失函数

**MSELoss**
- **作用**：均方误差损失（Mean Squared Error Loss），用于回归任务，衡量预测值与真实值之间的均方差。
- **数学公式**：
  $$
  \mathrm{MSELoss}(x, y) = \frac{1}{n} \sum_{i=1}^{n} (x_i - y_i)^2
  $$
  其中 $x$ 为预测值，$y$ 为真实值，$n$ 为样本数。
- **常见参数**：
  - `reduction`：指定输出结果的方式，取值有 `'mean'`（默认，取均值）、`'sum'`（求和）、`'none'`（不聚合，返回每个元素的损失）。

---

**L1Loss**
- **作用**：平均绝对误差损失（Mean Absolute Error Loss），用于回归任务，衡量预测值与真实值之间的绝对差。
- **数学公式**：
  $$
  \mathrm{L1Loss}(x, y) = \frac{1}{n} \sum_{i=1}^{n} |x_i - y_i|
  $$
  其中 $x$ 为预测值，$y$ 为真实值，$n$ 为样本数。
- **常见参数**：
  - `reduction`：指定输出结果的方式，取值同上：`'mean'`（默认）、`'sum'`、`'none'`。

---